6-16
前端：
1. 实现侧边栏、导航栏和主界面，添加路由、状态信息的配置，实现用户登录功能。
2. 添加了用户名显示，用户退出功能，持久化保存token和用户信息
3. 设置前置守卫，根据token判断是否登录，如果登录，则放行，否则跳转至login界面

后端：
1. 实现登录接口，设置过滤器JwtTokenAdminInterceptor，处理未登录情况，没有登录则创建一个token
2. 实现全局异常处理器GlobalExceptionHandle

前后端联调实现登录功能


6-17
后端：
1. 添加PageResult返回值，为分页查询的对象
2. 添加分页查询岗位的接口，新增Job对象，用来表示岗位信息

新增爬虫功能（crawl文件夹）
1. 使用pymysql操纵数据库，database包定义了连接池对象、init数据库方法、实体父类entity和两个实体类company和job
2. utils工具包configLoader能够自动加载yml配置文件，cache能够将循环遍历索引持久化保存，爬虫中断后可恢复
3. crawl中token能够获取cookie，requestHelper封装了查询接口，query实现将输入转化为查询的params，api提供查询工作的接口，main为爬虫主程序入口

